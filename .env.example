# The directory to store the local storage cache.
LLAMAINDEX_STORAGE_CACHE_DIR=.cache

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You're a helpful assistant!"

# The system prompt for the AI model.
LLAMAINDEX_SYSTEM_PROMPT="you are an assistant. Always use data_query_engine to answer the user's questions, and query for documents from your data source"

AZURE_AI_SEARCH_ENDPOINT=https://<service-name>.search.windows.net
AZURE_OPENAI_ENDPOINT=https://<service-name>.openai.azure.com/
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4
AZURE_API_VERSION=2024-09-01-preview
AZURE_AI_SEARCH_INDEX_NAME=llamaindex-vector-search
AZURE_LOG_LEVEL=info

# For local development, you can provide API keys for the services below.
# Make sure to keep these keys secret and never expose them in public repositories.
AZURE_AI_SEARCH_KEY=
OPENAI_API_KEY=