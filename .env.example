# The directory to store the local storage cache.
LLAMAINDEX_STORAGE_CACHE_DIR=.cache

# LLAMAINDEX_FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
LLAMAINDEX_FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You're a helpful assistant!"

# The system prompt for the AI model.
LLAMAINDEX_SYSTEM_PROMPT="you are an assistant. Always use data_query_engine to answer the user's questions, and query for documents from your data source"

# The backend URI for the Azure Container Apps service.
AZURE_AI_SEARCH_ENDPOINT=https://<service-name>.search.windows.net
AZURE_OPENAI_ENDPOINT=https://<service-name>.openai.azure.com/
OPENAI_API_VERSION="2024-02-15-preview"

# For local development, you can provide API keys for the services below.
# Make sure to keep these keys secret and never expose them in public repositories.
AZURE_AI_SEARCH_KEY=
OPENAI_API_KEY=

# Customize the deployment for the OpenAI text embedding model and chat model.
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_API_VERSION=2024-10-01-preview
AZURE_AI_SEARCH_INDEX_NAME=llamaindex-vector-search
AZURE_AI_SEARCH_CHUNK_FIELD="chunk"
AZURE_AI_SEARCH_DOC_ID_FIELD="doc_id"
AZURE_AI_SEARCH_EMBEDDING_FIELD="embedding"
AZURE_AI_SEARCH_ID_FIELD="id"
AZURE_AI_SEARCH_METADATA_FIELD="metadata"

# Optional: Set the log level for the Azure SDKs.
AZURE_LOG_LEVEL=info